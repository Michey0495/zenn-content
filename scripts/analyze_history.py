"""
Claude Codeå±¥æ­´åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨˜äº‹ãƒã‚¿ã‚’æŠ½å‡ºã™ã‚‹ã€‚
æ©Ÿå¯†æƒ…å ±ã¯è‡ªå‹•çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ã€‚
"""
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any
from collections import Counter

from config import (
    CLAUDE_HISTORY,
    CLAUDE_STATS,
    CLAUDE_PROJECTS,
    ZSH_HISTORY,
    SENSITIVE_KEYWORDS,
    EXCLUDED_PATH_PATTERNS,
    DAYS_TO_ANALYZE,
)


def sanitize_text(text: str) -> str:
    """æ©Ÿå¯†æƒ…å ±ã‚’é™¤å»ã™ã‚‹"""
    result = text

    # ãƒ‘ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
    for pattern in EXCLUDED_PATH_PATTERNS:
        result = re.sub(pattern, "[REDACTED_PATH]/", result)

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç½®æ›
    for keyword in SENSITIVE_KEYWORDS:
        result = re.sub(
            rf'\b{re.escape(keyword)}\b',
            '[ä¼æ¥­å]',
            result,
            flags=re.IGNORECASE
        )

    # çµ¶å¯¾ãƒ‘ã‚¹ã‚’ç›¸å¯¾ãƒ‘ã‚¹é¢¨ã«å¤‰æ›
    result = re.sub(
        r'/Users/[^/]+/',
        '~/',
        result
    )

    return result


def load_claude_history(days: int = DAYS_TO_ANALYZE) -> list[dict[str, Any]]:
    """Claude Codeå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€"""
    if not CLAUDE_HISTORY.exists():
        return []

    cutoff = datetime.now() - timedelta(days=days)
    cutoff_ts = cutoff.timestamp() * 1000  # ãƒŸãƒªç§’

    entries = []
    with open(CLAUDE_HISTORY, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                entry = json.loads(line.strip())
                if entry.get('timestamp', 0) >= cutoff_ts:
                    # æ©Ÿå¯†æƒ…å ±ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚º
                    entry['display'] = sanitize_text(entry.get('display', ''))
                    entry['project'] = sanitize_text(entry.get('project', ''))
                    entries.append(entry)
            except json.JSONDecodeError:
                continue

    return entries


def load_stats_cache() -> dict[str, Any]:
    """ä½¿ç”¨çµ±è¨ˆã‚’èª­ã¿è¾¼ã‚€"""
    if not CLAUDE_STATS.exists():
        return {}

    with open(CLAUDE_STATS, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_zsh_history(days: int = DAYS_TO_ANALYZE) -> list[str]:
    """zshå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€ï¼ˆClaude Codeé–¢é€£ã®ã¿ï¼‰"""
    if not ZSH_HISTORY.exists():
        return []

    # Claude Codeé–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    keywords = ['claude', 'npx', 'mcp', 'anthropic', 'zenn', 'git push']

    commands = []
    with open(ZSH_HISTORY, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            # zshå±¥æ­´å½¢å¼: : timestamp:0;command
            if ';' in line:
                cmd = line.split(';', 1)[1].strip()
            else:
                cmd = line.strip()

            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if any(kw in cmd.lower() for kw in keywords):
                sanitized = sanitize_text(cmd)
                if sanitized not in commands:
                    commands.append(sanitized)

    return commands[-100:]  # ç›´è¿‘100ä»¶


def extract_features_from_history(entries: list[dict]) -> dict[str, Any]:
    """å±¥æ­´ã‹ã‚‰ç‰¹å¾´ã‚’æŠ½å‡ºã™ã‚‹"""
    features = {
        "commands_used": Counter(),
        "skills_used": Counter(),
        "patterns": [],
        "heavy_usage_days": [],
        "unique_workflows": [],
    }

    for entry in entries:
        display = entry.get('display', '')

        # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã®æŠ½å‡º
        commands = re.findall(r'/(\w+)', display)
        for cmd in commands:
            features["commands_used"][cmd] += 1

        # ã‚¹ã‚­ãƒ«/ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ¤œå‡º
        if 'agent team' in display.lower():
            features["patterns"].append("Agent Teamsä½¿ç”¨")
        if 'tmux' in display.lower():
            features["patterns"].append("tmuxåˆ†å‰²")
        if 'ã‚¹ãƒ©ã‚¤ãƒ‰' in display or 'slide' in display.lower():
            features["patterns"].append("ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆ")
        if 'mcp' in display.lower():
            features["patterns"].append("MCPé€£æº")

    return features


def extract_topic_candidates(
    history: list[dict],
    stats: dict,
    zsh_commands: list[str]
) -> list[dict[str, Any]]:
    """è¨˜äº‹ãƒã‚¿å€™è£œã‚’æŠ½å‡ºã™ã‚‹"""
    candidates = []
    features = extract_features_from_history(history)

    # 1. ã‚ˆãä½¿ã†ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰ãƒã‚¿ã‚’ç”Ÿæˆ
    for cmd, count in features["commands_used"].most_common(5):
        if count >= 2:
            candidates.append({
                "type": "command_usage",
                "title": f"/{cmd}ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã„å€’ã—ã¦ã¿ãŸ",
                "source": f"ä½¿ç”¨å›æ•°: {count}å›",
                "priority": min(count, 10),
                "tags": ["claudecode", "cli", "tips"],
            })

    # 2. ä½¿ç”¨çµ±è¨ˆã‹ã‚‰ãƒã‚¿ã‚’ç”Ÿæˆ
    daily_activity = stats.get("dailyActivity", [])
    for day in daily_activity:
        if day.get("messageCount", 0) > 1000:
            candidates.append({
                "type": "heavy_usage",
                "title": f"Claude Codeã§{day['messageCount']}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ã£ãŸæ—¥ã®è¨˜éŒ²",
                "source": f"æ—¥ä»˜: {day['date']}",
                "priority": 8,
                "tags": ["claudecode", "productivity", "experiment"],
            })

    # 3. ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ãƒã‚¿ã‚’ç”Ÿæˆ
    unique_patterns = list(set(features["patterns"]))
    pattern_topics = {
        "Agent Teamsä½¿ç”¨": {
            "title": "Agent Teamsã§ä¸¦åˆ—é–‹ç™ºã—ã¦ã¿ãŸè©±",
            "tags": ["claudecode", "agentteams", "automation"],
        },
        "tmuxåˆ†å‰²": {
            "title": "tmuxÃ—Claude Codeã§ç”»é¢åˆ†å‰²é‹ç”¨ã®ã‚³ãƒ„",
            "tags": ["claudecode", "tmux", "workflow"],
        },
        "ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆ": {
            "title": "Claude Codeã§ã‚¹ãƒ©ã‚¤ãƒ‰è‡ªå‹•ç”Ÿæˆã™ã‚‹æ–¹æ³•",
            "tags": ["claudecode", "pptx", "automation"],
        },
        "MCPé€£æº": {
            "title": "MCPé€£æºã§åºƒãŒã‚‹Claude Codeã®å¯èƒ½æ€§",
            "tags": ["claudecode", "mcp", "integration"],
        },
    }

    for pattern in unique_patterns:
        if pattern in pattern_topics:
            topic = pattern_topics[pattern]
            candidates.append({
                "type": "pattern",
                "title": topic["title"],
                "source": f"æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern}",
                "priority": 7,
                "tags": topic["tags"],
            })

    # 4. zshã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰ãƒã‚¿ã‚’ç”Ÿæˆ
    if any('skill' in cmd.lower() for cmd in zsh_commands):
        candidates.append({
            "type": "skill_creation",
            "title": "Claude Codeã‚¹ã‚­ãƒ«ä½œæˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹",
            "source": "ã‚¹ã‚­ãƒ«é–¢é€£ã‚³ãƒãƒ³ãƒ‰æ¤œå‡º",
            "priority": 6,
            "tags": ["claudecode", "skill", "customization"],
        })

    # é‡è¤‡é™¤å»ã¨å„ªå…ˆåº¦ã‚½ãƒ¼ãƒˆ
    seen_titles = set()
    unique_candidates = []
    for c in sorted(candidates, key=lambda x: -x["priority"]):
        if c["title"] not in seen_titles:
            seen_titles.add(c["title"])
            unique_candidates.append(c)

    return unique_candidates


def analyze() -> dict[str, Any]:
    """ãƒ¡ã‚¤ãƒ³åˆ†æé–¢æ•°"""
    print("ğŸ“Š å±¥æ­´åˆ†æã‚’é–‹å§‹...")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    history = load_claude_history()
    print(f"  - Claude Codeå±¥æ­´: {len(history)}ä»¶")

    stats = load_stats_cache()
    daily_count = len(stats.get("dailyActivity", []))
    print(f"  - ä½¿ç”¨çµ±è¨ˆ: {daily_count}æ—¥åˆ†")

    zsh_commands = load_zsh_history()
    print(f"  - zshå±¥æ­´: {len(zsh_commands)}ä»¶")

    # ãƒã‚¿æŠ½å‡º
    candidates = extract_topic_candidates(history, stats, zsh_commands)
    print(f"  - ãƒã‚¿å€™è£œ: {len(candidates)}ä»¶")

    return {
        "analyzed_at": datetime.now().isoformat(),
        "history_count": len(history),
        "stats_days": daily_count,
        "candidates": candidates,
    }


if __name__ == "__main__":
    result = analyze()
    print("\nğŸ“ æŠ½å‡ºã•ã‚ŒãŸãƒã‚¿å€™è£œ:")
    for i, c in enumerate(result["candidates"], 1):
        print(f"  {i}. {c['title']} (å„ªå…ˆåº¦: {c['priority']})")
